# Pipeline Configuration for Clean GWOSC Downloader
# This config integrates the clean downloader with the existing pipeline

# Data directories (compatible with existing pipeline)
downloader:
  data_directories:
    raw_data: ./data/raw
    processed_data: ./data/processed
    manifest_file: ./data/download_manifest.json

  # Data parameters
  sample_rate: 4096  # Hz
  duration: 32       # seconds

  # Science mode validation
  science_min_coverage: 0.80  # Minimum fraction of segment in science mode

  # Download parameters
  download_parameters:
    max_concurrent: 4
    timeout_seconds: 60
    retry_attempts: 3
    retry_delay: 1.0

  # Signal download settings
  signals:
    # Specific events to download (if empty, will auto-discover)
    events: []
    
    # Detectors to download
    detectors: [H1] # Focus on H1 only - lower noise floor
    
    # Runs to search for events (if auto-discovery)
    runs: [O1, O2, O3a, O3b, O4a]

  # Noise download settings
  noise:
    # Runs to sample noise from
    runs: [O1, O2, O3a, O3b]
    
    # Detectors to download
    detectors: [H1] # Focus on H1 only - lower noise floor
    
    # Number of segments per run per detector
    segments_per_run: 500 # ~2000 total noise segments (500 per run Ã— 4 runs)
    
    # Minimum gap between segments (seconds)
    min_gap: 64

# Preprocessing configuration - EC2-EQUIVALENT APPROACH
preprocessing:
  cwt:
    sample_rate: 4096
    downsample_factor: 4  # CRITICAL: EC2-style downsampling (4096 Hz -> 1024 Hz)
    target_height: 8  # Match EC2 dimensions
    target_width: 4096  # Match EC2 dimensions
    use_analytic: false  # Use standard Morlet wavelet
    fmin: 20.0  # Match EC2 frequency range
    fmax: 512.0  # Match EC2 frequency range
    wavelet: 'morl'  # Standard Morlet wavelet (legacy approach)

# Model configuration - Updated for legacy CWT approach
model:
  type: 'cwt_lstm'
  input_height: 8  # Match EC2 dimensions
  input_width: 4096  # Match EC2 dimensions
  latent_dim: 32
  lstm_hidden: 64
  dropout: 0.0  # No dropout - matches legacy model exactly
  
  save:
    model_dir: 'models'  # Will be updated to run-specific path
    best_model_name: 'best_model.pth'
    final_model_name: 'final_model.pth'
    save_every_n_epochs: 5
    save_best: true
    
  anomaly_detection:
    threshold_method: 'percentile'  # Options: 'percentile', 'iqr', 'fixed'
    threshold_percentile: 95.0      # For percentile method
    threshold_multiplier: 1.5       # For IQR method
    fixed_threshold: 0.5            # For fixed method
    reconstruction_error_threshold: null  # Set to null for automatic threshold calculation
    scoring_strategy: 'mean'       # Options: 'mean', 'percentile_99', 'max', 'top_k'

# Training configuration - Updated to match legacy approach
training:
  batch_size: 1  # Match EC2 batch size exactly
  learning_rate: 0.001  # Match EC2 learning rate exactly
  num_epochs: 20  # Match EC2 epochs exactly
  early_stopping_patience: 3
  early_stopping_min_delta: 0.001  # Minimum improvement threshold
  early_stopping_monitor: 'train_loss'  # Monitor training loss instead of validation
  validation_split: 0.0  # Disable validation to match legacy approach
  optimizer: 'sgd'  # Use SGD like legacy - more stable for autoencoders
  momentum: 0.9  # SGD momentum
  weight_decay: 0.00001  # SGD weight decay (1e-5 as decimal)
  loss_function: 'mse'
  scheduler: 'reduce_on_plateau'

# Pipeline configuration
pipeline:
  run_name: 'clean_gwosc_pipeline'
  description: 'Pipeline using clean GWOSC downloader'
  version: '2.0.0'
  
  data_flow:
    preprocessed_data_dir: 'data/processed'
    train_on_noise_only: true
    sampling_strategy: 'conservative'  # Options: conservative (5), moderate (10), aggressive (20)
